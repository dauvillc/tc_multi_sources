encoder:
  _target_: multi_sources.models.general_backbone.MultisourceGeneralBackbone
  metadata_dim: ${lightning_module.metadata_dim}
  values_dim: ${lightning_module.values_dim}
  n_blocks: 8
  layers:
    windowed_self_attention:
      layer_class:
        _target_: hydra.utils.get_class
        path: multi_sources.models.attention.AdaptiveValuesMetadataAttention
      inner_dim: 512
      num_heads: 8
      window_size: 3
    ff1:
      layer_class:
        _target_: hydra.utils.get_class
        path: multi_sources.models.small_layers.FeedForward
      inner_dim: 512

decoder:
  _target_: multi_sources.models.general_backbone.MultisourceGeneralBackbone
  metadata_dim: ${lightning_module.metadata_dim}
  values_dim: ${lightning_module.values_dim}
  n_blocks: 6
  layers:
    windowed_self_attention:
      layer_class:
        _target_: hydra.utils.get_class
        path: multi_sources.models.attention.AdaptiveValuesMetadataAttention
      inner_dim: 512
      num_heads: 8
      window_size: 3
    ff1:
      layer_class:
        _target_: hydra.utils.get_class
        path: multi_sources.models.small_layers.FeedForward
      inner_dim: 512
