# Train dataset
train:
  _target_: multi_sources.data_processing.multi_source_dataset.MultiSourceDataset
  dataset_dir: ${paths.preprocessed_dataset}
  split: train
  included_variables_dict:
    _target_: multi_sources.data_processing.utils.read_variables_dict
    variables_dict: ${sources}
  # Maximum difference of time in hours between an observation's time
  # and the sample's reference time.
  dt_max: ???
  # Minimum number of sources that must be available in a sample
  # for it to be included in the dataset.
  min_available_sources: ???
  # Minimum number of sources of each type that must be available in a sample
  # for it to be included in the dataset.
  # Unspecified source types means at least 0 sources of that type (no restriction).
  source_types_min_avail: {}
  # For each source type, max number of observations that can be included for each
  # source of that type.
  source_types_max_avail: {}
  # Number of workers for the data loading
  num_workers: ${dataloader.num_workers}
  # Dict {source_type: proba} to randomly drop sources
  # of a given type with a given probability.
  # For example, to drop the IR and ERA5 sources half the time:
  # randomly_drop_sources:
  #   tc_primed_era5: 0.5
  #   tc_primed_infrared: 0.5
  randomly_drop_sources: {}
  # List of source types to forcefully drop. Source types listed here
  # can be dropped even below their values in source_types_min_avail.
  force_drop_sources: []
  # By default, don't select the most recent sources
  select_most_recent: false
  # Whether to mask the spatial coordinates of the sources
  mask_spatial_coords: []
  # Whether to do forecasting
  forecasting_lead_time: null
  forecasting_sources: null
  # Data augmentation to apply
  data_augmentation: ${data_augmentation}

# Validation dataset
val:
  _target_: multi_sources.data_processing.multi_source_dataset.MultiSourceDataset
  dataset_dir: ${paths.preprocessed_dataset}
  split: val
  included_variables_dict:
    _target_: multi_sources.data_processing.utils.read_variables_dict
    variables_dict: ${sources}
  dt_max: ${dataset.train.dt_max}
  min_available_sources: ${dataset.train.min_available_sources}
  source_types_min_avail: ${dataset.train.source_types_min_avail}
  source_types_max_avail: ${dataset.train.source_types_max_avail}
  num_workers: ${dataset.train.num_workers}
  randomly_drop_sources: ${dataset.train.randomly_drop_sources}
  force_drop_sources: ${dataset.train.force_drop_sources}
  select_most_recent: ${dataset.train.select_most_recent}
  forecasting_lead_time: ${dataset.train.forecasting_lead_time}
  forecasting_sources: ${dataset.train.forecasting_sources}
  mask_spatial_coords: ${dataset.train.mask_spatial_coords}
  data_augmentation: null

# Test dataset
test:
  _target_: multi_sources.data_processing.multi_source_dataset.MultiSourceDataset
  dataset_dir: ${paths.preprocessed_dataset}
  split: test
  included_variables_dict:
    _target_: multi_sources.data_processing.utils.read_variables_dict
    variables_dict: ${sources}
  dt_max: ${dataset.train.dt_max}
  min_available_sources: ${dataset.train.min_available_sources}
  source_types_min_avail: ${dataset.train.source_types_min_avail}
  source_types_max_avail: ${dataset.train.source_types_max_avail}
  num_workers: ${dataset.train.num_workers}
  randomly_drop_sources: ${dataset.train.randomly_drop_sources}
  force_drop_sources: ${dataset.train.force_drop_sources}
  select_most_recent: ${dataset.train.select_most_recent}
  forecasting_lead_time: ${dataset.train.forecasting_lead_time}
  forecasting_sources: ${dataset.train.forecasting_sources}
  mask_spatial_coords: ${dataset.train.mask_spatial_coords}
  data_augmentation: null