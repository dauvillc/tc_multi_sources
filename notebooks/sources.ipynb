{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2f43ce-7269-4c19-b2f6-3340878c7e8f",
   "metadata": {},
   "source": [
    "# Imports, setup and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69879e6c-ab1d-4dc6-a028-b6aec60bfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97a55b-7c23-498c-a986-c828aa4780d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2122fbc-ad92-4c00-87b3-9276dcc4b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5b3bd-6129-413a-abdd-60d8b5f6d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context initialization\n",
    "os.environ['NEWSCRATCH'] = \"/lustre/fsn1/projects/rech/xyw/ute68qj\"\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"preproc\", overrides=[\"paths=local\"])\n",
    "    paths = cfg['paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2a30c-e081-4bf4-91b2-079d95f59c94",
   "metadata": {},
   "source": [
    "# Looking at the available sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643c38b-f8cf-4175-841d-1006614b389f",
   "metadata": {},
   "source": [
    "Let's first load the samples metadata file, which gives all of the metadata for every sample in the train, val and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76359cf0-db51-4702-b7ad-aef3f671e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(paths['preprocessed_dataset'])\n",
    "df = pd.read_csv(dataset_dir / 'train.csv', parse_dates=[\"time\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f3057-f617-49f1-91a9-db883208d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2c98e-7508-4893-9141-0a5b2fbcb76b",
   "metadata": {},
   "source": [
    "**Important**: by default, this notebook will use ALL of the preprocessed data, i.e. all sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0acaa-d056-4bdf-859b-c9f03eb63a41",
   "metadata": {},
   "source": [
    "## Repartition by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb992a1-e4b8-44fa-9039-f4c68d4275e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x='source_name')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc7308-b440-4a6b-a3e6-8a69af94f668",
   "metadata": {},
   "source": [
    "While the ERA5 states and infrared observations are each considered as a source on its own, the passive microwave and radar observations are split into one source per satellite, sensor and swath."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6953ae5-e073-497d-bfb9-03e7f970f1c4",
   "metadata": {},
   "source": [
    "## Repartition by satellite over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b06d38-2d92-4a5e-9d34-f6ba180052e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of the dataset made up of pmw and radar data only.\n",
    "pmw_df = df[~(df['source_name'].str.contains('infrared') | df['source_name'].str.contains('era5'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d80417-34d6-4ea7-8ff2-42c906327055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of observations per month for each source\n",
    "month = pmw_df.time.dt.to_period('M')\n",
    "sat = pmw_df.source_name.apply(lambda s: s.split('_')[3].split('_')[0])\n",
    "monthly_obs = pmw_df.groupby([sat, month])['sid'].count().rename('Monthly overpasses').reset_index()\n",
    "monthly_obs['time'] = monthly_obs.time.dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f446af1-e044-46df-974e-b46b6548b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(monthly_obs, x='time', y='Monthly overpasses', hue='source_name', style='source_name')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb6fe5-f951-4c79-a5f0-4b4678bca549",
   "metadata": {},
   "source": [
    "Let's also look at the counts per sensor and satellite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05e48a-ea2c-4934-bd93-479e4cb7fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensat = pmw_df.source_name.apply(lambda s: '_'.join(s.split('_')[3:5]))\n",
    "monthly_obs = df.groupby([sensat, month])['sid'].count().rename('Monthly overpasses').reset_index()\n",
    "monthly_obs['time'] = monthly_obs.time.dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d8a47-9381-4a74-ba4f-c8cc6539d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(monthly_obs, x='time', y='Monthly overpasses', hue='source_name', style='source_name')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3a080-be19-444a-9797-7e13acad36c6",
   "metadata": {},
   "source": [
    "The observations from the sensor/satellite pair ```SSMIS_F19``` abruptly end in early 2016, while ```ATMS_NOAA20``` only started returning observations in late 2017.  \n",
    "Let's take a clearer look at the time span of each sensor / satellite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ba28b-529a-4689-8c12-7b00eb510731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the earliest and latest dates for each satellite/sensor pair\n",
    "gpby = pmw_df.groupby(sensat)\n",
    "start_dates = gpby['time'].min()\n",
    "end_dates = gpby['time'].max()\n",
    "timeline_df = pd.merge(start_dates, end_dates, left_index=True, right_index=True, suffixes=['_start', '_end'])\n",
    "timeline_df = timeline_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbee608-3939-437a-9f77-5d1266db9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.timeline(timeline_df.sort_values('time_start'),\n",
    "                  x_start=\"time_start\",\n",
    "                  x_end=\"time_end\",\n",
    "                  y=\"source_name\",\n",
    "                  text=\"source_name\",\n",
    "                  color_discrete_sequence=[\"tan\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14324e23-87ea-48d5-a7a6-2da95f014414",
   "metadata": {},
   "source": [
    "# From dataset to samples\n",
    "We now need to define what a *sample* means. We can define a sample from a reference observation:  \n",
    "Let $x_0 \\in S_0$ be an observation from the source $S_0$; let $t_0$ be the time of that observation.  \n",
    "We'll define the sample referenced by $x_0$ as:  \n",
    "$$\n",
    "x = \\{x_k \\in S_k;\\quad x_k = \\text{arg min}_{u_k\\in S_k; t_{u_k} \\leq t_0}(t_0 - t_{u_k})\\}\n",
    "$$\n",
    "i.e. for each source, we'll use the observation older than $t_0$ that is closest to $t_0$. Observations from different storms are never mixed.  \n",
    "Since observations that are far away in time are less correlated, we'll introduce a maximum time delta between $t_0$ and $t_k$ for $x_k$ to be actually included in $x$:\n",
    "$$\n",
    "x_{\\text{filtered}} = \\{x_k \\in x; \\Delta t_k := t_0 - t_k \\leq \\Delta t_{max}\\}\n",
    "$$\n",
    "A larger $\\Delta t_{max}$ will allow more source to appear in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6523441e-59e2-4441-bd64-477638d74b41",
   "metadata": {},
   "source": [
    "## Isolating samples for which specific sources are available\n",
    "We may need during training and evaluation to only use samples for which at least a certain set of sources is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b01cb6-4760-4feb-b32b-b9192748f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sids = df['sid'].unique()\n",
    "unique_sources = df['source_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6fe47-b98f-4da4-9fff-f0f8f5e08d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name_col = df['source_name'].to_numpy()\n",
    "sid_col = df['sid'].to_numpy()\n",
    "time_col = df['time'].to_numpy()\n",
    "\n",
    "# maps {sid: sid_mask} and {source_name: source_mask}\n",
    "# We precompute those as they will be reused multiple times each,\n",
    "# and bypassing pandas to use numpy directly is much faster.\n",
    "source_name_mask = {}\n",
    "for source_name in unique_sources:\n",
    "    source_name_mask[source_name] = source_name_col == source_name\n",
    "sid_mask = {}\n",
    "for sid in unique_sids:\n",
    "    sid_mask[sid] = sid_col == sid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626775d6-a765-4815-af3b-8f3841b71310",
   "metadata": {},
   "source": [
    "Let's now compute the available sources for all samples in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e15fb-e212-4e28-b876-5707a2597233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_source_available(ref_obs, source_name, dt_max):\n",
    "    \"\"\"Given a row in the metadata df which defines a sample (reference\n",
    "    observation) and a source, returns 1 if the source is present in the\n",
    "    sample and 0 otherwise.\"\"\"\n",
    "    t0 = ref_obs['time']\n",
    "    # Compute the oldest time an observation can have to respect the time delta constraint.\n",
    "    min_t = t0 - dt_max\n",
    "    # Isolate the times of observations corresponding to the correct sid and source\n",
    "    sid = ref_obs['sid']\n",
    "    times = time_col[sid_mask[sid] & source_name_mask[source_name]]\n",
    "    # Check for times that respect the time delta constraint\n",
    "    return int(((times <= t0) & (times >= min_t)).sum() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c480a-9185-401a-8e7d-50da96bee2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sources_availability(dt_max):\n",
    "    \"\"\"Returns a dataframe D with one column per source, and one row\n",
    "    per sample in df, such that D[i, s] is 1 if source s is available\n",
    "    at sample i and 0 otherwise.\"\"\"\n",
    "    dt_max = pd.Timedelta(hours=dt_max)\n",
    "    availability = {}  # {source: [availability flag for each sample]}\n",
    "    for source in unique_sources:\n",
    "        availability[source] = df.apply(is_source_available, args=[source, dt_max], axis='columns')\n",
    "    return pd.DataFrame(availability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b328d-0330-43da-b72d-3f49fb752735",
   "metadata": {},
   "source": [
    "Let's check as an example the available sources for $\\Delta t_{max}=24h$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7f84d-6f41-4cb2-aab4-e3e7d00d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_24h = sources_availability(24)\n",
    "avail_24h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2a0e0-0120-425a-903b-13f2b01d312c",
   "metadata": {},
   "source": [
    "We can deduce from this the number of available sources for each sample, if which sources are present doesn't matter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b85474-c722-4833-a6ef-8eb28be1fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_counts_24h = avail_24h.sum(axis=1)\n",
    "avail_counts_24h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490407b-b6fb-44b9-9efb-1422255dfb36",
   "metadata": {},
   "source": [
    "## Statistical presence of the sources\n",
    "We'll thus now study how many sources are present statistically in the samples depending on $\\Delta t_{max}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6b382-ef2a-407a-88b4-72b347cca40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sources_availability_frequency(dt_max):\n",
    "    \"\"\"Returns a dataframe D with one column per source, and one row\n",
    "    per sample in df, such that D[i, s] is 1 if source s is available\n",
    "    at sample i and 0 otherwise.\"\"\"\n",
    "    dt_max = pd.Timedelta(hours=dt_max)\n",
    "    availability = defaultdict(int)  # {source: frequency of presence}\n",
    "    for source in unique_sources:\n",
    "        availability[source] = df.apply(is_source_available, args=[source, dt_max], axis='columns').mean()\n",
    "    return availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7fe2a-dedb-42ad-8167-4d0bb6573e47",
   "metadata": {},
   "source": [
    "We can now plot the frequency at which a source is available in the samples, depending on $\\Delta t_{max}$:  \n",
    "(this can take a while to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036b7c5-e118-4e16-b464-b3f1cecd45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_freq = defaultdict(list)  # {source: [freq for each dt_max]}\n",
    "dt_max_values = np.arange(1, 25, 2)\n",
    "for dt_max in dt_max_values:\n",
    "    print(f\"Computing availability for dt_max={dt_max}h\")\n",
    "    avail = sources_availability_frequency(dt_max)\n",
    "    for source in unique_sources:\n",
    "        avail_freq[source].append(avail[source])\n",
    "avail_freq = pd.DataFrame(avail_freq)\n",
    "avail_freq['dt_max'] = dt_max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770091f1-b734-4f68-ac77-fa2bf7fb935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2803872-692c-4d95-ba66-598ed5f3c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    avail_freq.melt(id_vars=['dt_max'], var_name='source_name', value_name='frequency'),\n",
    "    x='dt_max',\n",
    "    y='frequency',\n",
    "    hue='source_name',\n",
    "    style='source_name'\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
