{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1a0e06-9fef-4a7b-af9c-5efd4fff0834",
   "metadata": {},
   "source": [
    "# Checking the preprocessed data\n",
    "In this notebook, we'll analyze the preprocessed datasets to check their quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5d321-b91f-45a2-aed1-b0b66c4c9af7",
   "metadata": {},
   "source": [
    "# Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5b22ba-6c77-4e15-bb4e-c6d2dde5f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cdauvill/inria/multi_sources\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158e349c-f1d8-46c5-a718-be9349a89b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6701634-e614-4ee2-9c5f-2f29eb4795e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from netCDF4 import Dataset\n",
    "from pathlib import Path\n",
    "from multi_sources.data_processing.multi_source_dataset import MultiSourceDataset\n",
    "from multi_sources.data_processing.utils import read_variables_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65eba5b-b849-4bd7-8fb9-f1410d4c7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context initialization\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"train\", overrides=[\"paths=local\", \"sources=all_sources\"])\n",
    "paths = cfg['paths']\n",
    "sources_cfg = cfg['sources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00eeec10-d8ad-4e59-8b3d-c541c7b22de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tc_primed': {'pmw': {'AMSR2_GCOMW1': {'S4': {'variables': ['TB_36.5H']}}, 'ATMS_NPP': {'S2': {'variables': ['TB_31.4QV']}}, 'GMI_GPM': {'S1': {'variables': ['TB_36.64H']}}, 'SSMIS_F16': {'S2': {'variables': ['TB_37.0H']}}, 'SSMIS_F17': {'S2': {'variables': ['TB_37.0H']}}, 'SSMIS_F18': {'S2': {'variables': ['TB_37.0H']}}}, 'infrared': {'variables': ['IRWIN']}, 'era5': {'variables': ['sst', 'pressure_msl', 'u_wind_10m', 'v_wind_10m']}, 'radar': {'GMI_GPM': {'KuGMI': {'variables': ['nearSurfPrecipTotRate', 'nearSurfPrecipTotRateSigma']}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7ac5c-2128-4505-80aa-2cf2e61bd200",
   "metadata": {},
   "source": [
    "# Building the dataset\n",
    "We'll use the ```MultiSourceDataset```, which is a map-style torch ```Dataset``` custom subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0bad641-ad5b-48be-b7bf-4014288331e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Browsing requested sources and loading metadata...\n",
      "train: Found 9 sources in the dataset.\n",
      "train: Computing sources availability...\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset_dir = paths['preprocessed_dataset']\n",
    "split = 'train'\n",
    "included_vars = read_variables_dict(sources_cfg)\n",
    "dataset = MultiSourceDataset(dataset_dir, split, included_vars, single_channel_sources=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e0161f-8d55-40ce-ab49-fe8a7371d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21286"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c843219-85f8-490e-8ea1-9eb6af5162eb",
   "metadata": {},
   "source": [
    "# Displaying a single sample\n",
    "We'll first have a look at a single sample yielded by the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13bc7c4a-d91a-44c1-8292-2ab41a8895cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(\u001b[38;5;241m17\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m sample \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m61\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# sample is a dict {source_name: map} where map is a dict containing\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# various information about the sample.\u001b[39;00m\n",
      "File \u001b[0;32m~/inria/multi_sources/multi_sources/data_processing/multi_source_dataset.py:246\u001b[0m, in \u001b[0;36mMultiSourceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    242\u001b[0m context_df \u001b[38;5;241m=\u001b[39m df[source\u001b[38;5;241m.\u001b[39mcontext_vars]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# context_vars[cvar] is a dict {dvar: value} for each data variable dvar\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# of the source. We want to obtain a tensor of shape\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# (n_context_vars * n_data_vars,)\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m CT \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcvar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdvar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdvar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcvar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_vars\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (n_data_vars, n_context_vars)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m CT \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(CT\u001b[38;5;241m.\u001b[39mflatten(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Load the variables in the order specified in the source\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/numpy/core/shape_base.py:445\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    443\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(17)\n",
    "sample = dataset[rng.integers(low=0, high=len(dataset), size=1)[0]]\n",
    "sample = dataset[61]\n",
    "# sample is a dict {source_name: map} where map is a dict containing\n",
    "# various information about the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c4f59-12eb-4d98-97d5-bbaadd34bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sample[list(sample.keys())[0]]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564d3c8-2f27-4511-b527-eedf87d9b4ea",
   "metadata": {},
   "source": [
    "## Composition\n",
    "Let's check which sources are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52910412-08db-491f-9d07-3cd2d5d3560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available sources:\")\n",
    "for sn in sample:\n",
    "    print(sn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0772181-d41c-4449-b123-8fb1718783eb",
   "metadata": {},
   "source": [
    "## Coordinates and land mask\n",
    "Let's select the a source from the ```AMSR2``` satellite, as it is the most frequently available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99fffc-b52b-4adf-800f-1fb5f0a1ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde8d62-8d1c-44d4-8659-0120b60ca554",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_source = sample['tc_primed_era5_sst']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca6fc5-35bf-4b7a-baf7-f8be7eb8fe8e",
   "metadata": {},
   "source": [
    "The ```coords``` tensor contains the latitude and longitude as the two channels of an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259ecb5-2b4c-4e21-8a10-1d569dd8da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = any_source['coords']\n",
    "lat, lon = c[0], c[1]\n",
    "plt.subplot(121)\n",
    "plt.imshow(lat)\n",
    "plt.subplot(122)\n",
    "plt.imshow(lon)\n",
    "# Time coordinate\n",
    "print(any_source['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6e25d-ba39-43a6-bcf2-b253583b46b4",
   "metadata": {},
   "source": [
    "```landmask``` is the land-sea mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261a376-ce4d-4a5a-aadb-ce47715de44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(any_source['landmask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858a5d9-4f58-4900-ac42-c899c2228b51",
   "metadata": {},
   "source": [
    "## Context variables\n",
    "Each source has its own set of context variables. All samples from a common source have the same context variables, but their values may change across samples.  \n",
    "For example, the context for microwave observations includes the frequency (in GHz) and four values in km characterizing the IFOV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24835ea6-cf7f-403d-838f-b8a4240855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_source['context']  # freq, IFOV_nadir_along_track, IFOV_nadir_across_track, IFOV_edge_along_track, IFOV_edge_across_track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf4c84-69a2-4332-a980-4b3b4b15fae5",
   "metadata": {},
   "source": [
    "## Values\n",
    "Let's now look at the values (i.e. the observation themselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e15558-5ae9-4563-80ff-9e5b65ba57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = any_source['values']\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abb0cb-89af-4bcf-8f2e-86162ff68180",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=v.shape[0], squeeze=False)\n",
    "for i in range(v.shape[0]):\n",
    "    axes[0, i].imshow(v[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
